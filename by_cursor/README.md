# ğŸ“„ HWP/HWPX Parser for Python

í•œê¸€ ë¬¸ì„œ íŒŒì¼(`.hwp`, `.hwpx`)ì„ íŒŒì‹±í•˜ì—¬ í…ìŠ¤íŠ¸, ë ˆì´ì•„ì›ƒ, ì¢Œí‘œ ì •ë³´, ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•˜ëŠ” Python ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

**LLM/RAG ì‹œìŠ¤í…œì— ìµœì í™”ëœ êµ¬ì¡°í™”ëœ ì¶œë ¥**ì„ ì œê³µí•©ë‹ˆë‹¤.

---

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

| ê¸°ëŠ¥ | ì„¤ëª… |
|------|------|
| ğŸ“ **í…ìŠ¤íŠ¸ ì¶”ì¶œ** | ë¬¸ë‹¨, í‘œ, ì œëª© ë“± ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ |
| ğŸ“ **ë ˆì´ì•„ì›ƒ ì •ë³´** | ë°”ìš´ë”© ë°•ìŠ¤, ì¢Œí‘œ, í¬ê¸° (mm ë‹¨ìœ„) |
| ğŸ“Š **í‘œ êµ¬ì¡°í™”** | ì œëª©/í—¤ë”/ë‚´ìš© ë¶„ë¦¬ (LLM ì¹œí™”ì ) |
| ğŸ–¼ï¸ **ì´ë¯¸ì§€ ì¶”ì¶œ** | ì„ë² ë””ë“œ ì´ë¯¸ì§€ ì¶”ì¶œ ë° ì¢Œí‘œ ì •ë³´ (NEW!) |
| ğŸ¨ **WMF/EMF ë³€í™˜** | ë²¡í„° ì´ë¯¸ì§€ë¥¼ PNGë¡œ ë³€í™˜ |
| ğŸ“· **OCR ì—°ë™** | ì™¸ë¶€ OCR ì„œë¹„ìŠ¤ ì—°ë™ì„ ìœ„í•œ JSON ì¶œë ¥ |
| ğŸ¨ **ì‹œê°í™”** | ë¬¸ì„œ ë ˆì´ì•„ì›ƒì„ ì´ë¯¸ì§€ë¡œ ì‹œê°í™” |
| ğŸ“‹ **ë‹¤ì–‘í•œ ì¶œë ¥** | JSON, Markdown, êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ |
| ğŸ“‘ **ë‹¤ì¤‘ í˜ì´ì§€** | ì—¬ëŸ¬ í˜ì´ì§€(ì„¹ì…˜) ìë™ ì²˜ë¦¬ |

---

## ğŸ“¦ ì„¤ì¹˜

### í•„ìˆ˜ ì˜ì¡´ì„±

```bash
pip install olefile Pillow
```

### ì„ íƒì  ì˜ì¡´ì„±

```bash
# WMF/EMF ë³€í™˜ì„ ìœ„í•´ (ì„ íƒ)
brew install imagemagick  # macOS
apt-get install imagemagick  # Ubuntu/Debian
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ê¸°ë³¸ ì‚¬ìš©ë²• (ì´ë¯¸ì§€ í¬í•¨)

```python
from hwpx_parser_cursor import parse_hwpx
from hwp_parser_cursor import parse_hwp
from document_extractor import extract_document_with_images, create_visualization_report

# HWPX íŒŒì¼ ì²˜ë¦¬
doc = parse_hwpx("document.hwpx")

# ì´ë¯¸ì§€ í¬í•¨ ì¶”ì¶œ
extracted = extract_document_with_images(
    doc,
    extract_images=True,           # ì´ë¯¸ì§€ ì¶”ì¶œ í™œì„±í™”
    save_images_dir="output/images"  # ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬
)

# HWP íŒŒì¼ ì²˜ë¦¬
doc = parse_hwp("document.hwp")
extracted = extract_document_with_images(doc, extract_images=True, save_images_dir="output/images")

# ê²°ê³¼ ì¶œë ¥
print(f"ìš”ì†Œ ìˆ˜: {len(extracted.elements)}")
print(f"í‘œ ìˆ˜: {len(extracted.tables)}")
print(f"ì´ë¯¸ì§€ ìˆ˜: {len(extracted.images)}")  # NEW!

# ì „ì²´ ë¦¬í¬íŠ¸ ìƒì„± (ì´ë¯¸ì§€ í¬í•¨)
create_visualization_report(extracted, "output/")
```

---

## ğŸ“– ìƒì„¸ ì‚¬ìš©ë²•

### 1. ë¬¸ì„œ íŒŒì‹±

```python
# HWPX (XML ê¸°ë°˜, Open Document Format)
from hwpx_parser_cursor import parse_hwpx

doc = parse_hwpx("/path/to/document.hwpx")
print(doc.title)
print(doc.to_text())
print(doc.to_markdown())
print(doc.to_json())

# HWP (OLE Compound Document Format)
from hwp_parser_cursor import parse_hwp

doc = parse_hwp("/path/to/document.hwp")
print(doc.title)
print(doc.to_text())
print(doc.to_markdown())
print(doc.to_json())
```

### 2. êµ¬ì¡°í™”ëœ ì •ë³´ ì¶”ì¶œ

```python
from document_extractor import extract_document_elements

extracted = extract_document_elements(doc)

# ê¸°ë³¸ ì •ë³´
print(f"ìš”ì†Œ ìˆ˜: {len(extracted.elements)}")
print(f"ì œëª© ìˆ˜: {len(extracted.headings)}")
print(f"í‘œ ìˆ˜: {len(extracted.tables)}")
print(f"í˜ì´ì§€ ìˆ˜: {len(extracted.pages)}")
```

### 3. ë°”ìš´ë”© ë°•ìŠ¤ ë° ì¢Œí‘œ

```python
for elem in extracted.elements:
    print(f"ìœ í˜•: {elem.element_type}")
    print(f"í…ìŠ¤íŠ¸: {elem.text}")
    print(f"ìœ„ì¹˜: ({elem.bbox.x}, {elem.bbox.y}) mm")
    print(f"í¬ê¸°: {elem.bbox.width} Ã— {elem.bbox.height} mm")
    print(f"í˜ì´ì§€: {elem.page + 1}")
```

### 4. í‘œ êµ¬ì¡°í™” (LLM/RAGìš©)

```python
for table in extracted.tables:
    print(f"í‘œ ì œëª©: {table.title}")
    print(f"í—¤ë”: {table.headers}")
    print(f"ë°ì´í„°: {table.rows}")
    
    # LLMìš© êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸
    print(table.to_structured_text())
    # ì¶œë ¥:
    # [í‘œ ì œëª©] ê´‘ê³ ì‹¬ì˜ì‹ ì²­ ì ‘ìˆ˜ì •ë³´
    # [í‘œ í—¤ë”] ì‹ ì²­ì | ì€í–‰ëª… | ë‹´ë‹¹ìëª…
    # [í–‰ 1] ì¤€ë²•ê°ì‹œì¸ | | ëª…ì¹­
    
    # Markdown í…Œì´ë¸”
    print(table.to_markdown())
```

---

## ğŸ†• ì´ë¯¸ì§€ ì¶”ì¶œ

### ê¸°ë³¸ ì´ë¯¸ì§€ ì¶”ì¶œ

```python
from image_extractor import extract_images_from_hwp, extract_images_from_hwpx

# HWP íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
images = extract_images_from_hwp("document.hwp")

# HWPX íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
images = extract_images_from_hwpx("document.hwpx")

# ì´ë¯¸ì§€ ì •ë³´ í™•ì¸
for img in images:
    print(f"ì´ë¯¸ì§€ ID: {img.bin_id}")
    print(f"íŒŒì¼ëª…: {img.filename}")
    print(f"í˜•ì‹: {img.format}")
    print(f"í¬ê¸°: {len(img.data):,} bytes")
    print(f"í•´ìƒë„: {img.pixel_width}Ã—{img.pixel_height} px")
    print(f"ë¬¸ì„œ ë‚´ ìœ„ì¹˜: ({img.x:.1f}, {img.y:.1f}) mm")
    print(f"ë¬¸ì„œ ë‚´ í¬ê¸°: {img.width:.1f}Ã—{img.height:.1f} mm")
    print(f"í˜ì´ì§€: {img.page + 1}")
    print()
    
    # ì´ë¯¸ì§€ ì €ì¥
    img.save("output/images/")
```

### ì´ë¯¸ì§€ì™€ í•¨ê»˜ ë¬¸ì„œ ì¶”ì¶œ

```python
from hwp_parser_cursor import parse_hwp
from document_extractor import extract_document_with_images

doc = parse_hwp("document.hwp")

# ì´ë¯¸ì§€ í¬í•¨ ì¶”ì¶œ
extracted = extract_document_with_images(
    doc,
    extract_images=True,              # ì´ë¯¸ì§€ ì¶”ì¶œ í™œì„±í™”
    save_images_dir="output/images"   # ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬
)

# ì¶”ì¶œëœ ì´ë¯¸ì§€ í™•ì¸
print(f"ì´ë¯¸ì§€ ìˆ˜: {len(extracted.images)}")
for img in extracted.images:
    print(f"  - {img.filename} ({img.format.upper()}, {img.file_size:,} bytes)")
    print(f"    ìœ„ì¹˜: ({img.bbox.x:.1f}, {img.bbox.y:.1f}) mm")
    print(f"    í˜ì´ì§€: {img.page + 1}")
```

### OCR ì—°ë™ìš© JSON ì¶œë ¥

ì´ë¯¸ì§€ ì¶”ì¶œ ì‹œ ìë™ìœ¼ë¡œ ìƒì„±ë˜ëŠ” `*_images.json` íŒŒì¼ì„ ì™¸ë¶€ OCR ì„œë¹„ìŠ¤ì™€ ì—°ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```json
{
  "document_title": "ë¬¸ì„œì œëª©",
  "image_count": 2,
  "images": [
    {
      "image_id": "BIN0001",
      "filename": "BIN0001.jpg",
      "format": "jpg",
      "class": "image",
      "bbox_mm": {
        "x": 20.0,
        "y": 50.0,
        "width": 150.0,
        "height": 100.0
      },
      "bbox_px": {
        "width": 2481,
        "height": 3508
      },
      "page": 0,
      "saved_path": "/path/to/BIN0001.jpg",
      "ocr_text": "",
      "ocr_confidence": 0.0
    }
  ]
}
```

### OCR ì—°ë™ ì˜ˆì‹œ

```python
import json

# 1. ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ë¡œë“œ
with open("output/document_images.json", "r", encoding="utf-8") as f:
    data = json.load(f)

# 2. ê° ì´ë¯¸ì§€ì— ëŒ€í•´ OCR ìˆ˜í–‰
for img in data["images"]:
    image_path = img["saved_path"]
    
    # ì™¸ë¶€ OCR í˜¸ì¶œ (ì˜ˆ: Tesseract, Cloud Vision API ë“±)
    # ocr_result = your_ocr_service.recognize(image_path)
    
    # ê²°ê³¼ ì €ì¥
    # img["ocr_text"] = ocr_result["text"]
    # img["ocr_confidence"] = ocr_result["confidence"]

# 3. ì—…ë°ì´íŠ¸ëœ ë©”íƒ€ë°ì´í„° ì €ì¥
with open("output/document_images_with_ocr.json", "w", encoding="utf-8") as f:
    json.dump(data, f, ensure_ascii=False, indent=2)
```

### WMF/EMF ë²¡í„° ì´ë¯¸ì§€ ë³€í™˜

```python
from image_extractor import extract_images_from_hwp

# WMF/EMFë¥¼ ìë™ìœ¼ë¡œ PNGë¡œ ë³€í™˜
images = extract_images_from_hwp("document.hwp")

for img in images:
    if img.format in ['wmf', 'emf']:
        print(f"ë²¡í„° ì´ë¯¸ì§€ ë°œê²¬: {img.filename}")
    
    # ë³€í™˜ê³¼ í•¨ê»˜ ì €ì¥
    img.save("output/images/", convert_vector=True)
```

---

## ğŸ“‘ í˜ì´ì§€ ì²˜ë¦¬ (ë‹¨ì¼ í˜ì´ì§€ vs ë‹¤ì¤‘ í˜ì´ì§€)

### âœ… ë‹¤ì¤‘ í˜ì´ì§€ ì§€ì›

ì´ íŒŒì„œëŠ” **ì—¬ëŸ¬ í˜ì´ì§€(ì„¹ì…˜)ë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬**í•©ë‹ˆë‹¤.

| íŒŒì„œ | ë‹¤ì¤‘ í˜ì´ì§€ ì§€ì› | ì²˜ë¦¬ ë°©ì‹ |
|------|-----------------|----------|
| **HWPX** | âœ… ì§€ì› | `section0.xml`, `section1.xml`... ìë™ íƒìƒ‰ |
| **HWP** | âœ… ì§€ì› | `BodyText/Section0`, `Section1`... ìˆœì°¨ ì²˜ë¦¬ |

### ë‹¨ì¼ í˜ì´ì§€ ì²˜ë¦¬

íŠ¹ì • í˜ì´ì§€ë§Œ ì²˜ë¦¬í•˜ê³  ì‹¶ì„ ë•Œ:

```python
from document_extractor import extract_document_with_images, visualize_elements

# ë¬¸ì„œ íŒŒì‹±
doc = parse_hwpx("multi_page_document.hwpx")
extracted = extract_document_with_images(doc, extract_images=True)

# í˜ì´ì§€ ìˆ˜ í™•ì¸
print(f"ì´ í˜ì´ì§€ ìˆ˜: {len(extracted.pages)}")

# íŠ¹ì • í˜ì´ì§€ì˜ ìš”ì†Œë§Œ í•„í„°ë§
page_num = 0  # ì²« ë²ˆì§¸ í˜ì´ì§€ (0ë¶€í„° ì‹œì‘)
page_elements = [e for e in extracted.elements if e.page == page_num]
print(f"í˜ì´ì§€ {page_num + 1}ì˜ ìš”ì†Œ ìˆ˜: {len(page_elements)}")

# íŠ¹ì • í˜ì´ì§€ì˜ ì´ë¯¸ì§€ë§Œ í•„í„°ë§
page_images = [img for img in extracted.images if img.page == page_num]
print(f"í˜ì´ì§€ {page_num + 1}ì˜ ì´ë¯¸ì§€ ìˆ˜: {len(page_images)}")

# íŠ¹ì • í˜ì´ì§€ë§Œ ì‹œê°í™”
visualize_elements(extracted, "page_1.png", page_num=0)  # ì²« ë²ˆì§¸ í˜ì´ì§€
visualize_elements(extracted, "page_2.png", page_num=1)  # ë‘ ë²ˆì§¸ í˜ì´ì§€
```

### ëª¨ë“  í˜ì´ì§€ ì²˜ë¦¬

ì—¬ëŸ¬ í˜ì´ì§€ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•  ë•Œ:

```python
from document_extractor import extract_document_with_images, create_visualization_report

# ë¬¸ì„œ íŒŒì‹± (ëª¨ë“  ì„¹ì…˜ ìë™ í¬í•¨)
doc = parse_hwpx("multi_page_document.hwpx")
extracted = extract_document_with_images(doc, extract_images=True, save_images_dir="output/images")

# ì „ì²´ í˜ì´ì§€ ì •ë³´
print(f"ì´ í˜ì´ì§€: {len(extracted.pages)}")
for page in extracted.pages:
    print(f"  í˜ì´ì§€ {page.page_num + 1}: {page.width}mm Ã— {page.height}mm")

# ëª¨ë“  í˜ì´ì§€ ì‹œê°í™” (ê° í˜ì´ì§€ë³„ ì´ë¯¸ì§€ ìƒì„±)
create_visualization_report(extracted, "output_dir/")
# ì¶œë ¥:
#   output_dir/ë¬¸ì„œëª…_page_001.png
#   output_dir/ë¬¸ì„œëª…_page_002.png
#   output_dir/ë¬¸ì„œëª…_page_003.png
#   output_dir/ë¬¸ì„œëª…_images.json (ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°)
#   output_dir/images/ (ì¶”ì¶œëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤)
#   ...
```

### í˜ì´ì§€ë³„ ì´ë¯¸ì§€ ì¶”ì¶œ

```python
# í˜ì´ì§€ë³„ë¡œ ì´ë¯¸ì§€ ê·¸ë£¹í™”
from collections import defaultdict

images_by_page = defaultdict(list)
for img in extracted.images:
    images_by_page[img.page].append(img)

# ê° í˜ì´ì§€ì˜ ì´ë¯¸ì§€ ì²˜ë¦¬
for page_num in sorted(images_by_page.keys()):
    images = images_by_page[page_num]
    print(f"\n=== í˜ì´ì§€ {page_num + 1}ì˜ ì´ë¯¸ì§€ ===")
    print(f"ì´ë¯¸ì§€ ìˆ˜: {len(images)}")
    
    for img in images:
        print(f"  - {img.filename} ({img.format.upper()})")
        print(f"    ìœ„ì¹˜: ({img.bbox.x:.1f}, {img.bbox.y:.1f}) mm")
        print(f"    í¬ê¸°: {img.bbox.width:.1f}Ã—{img.bbox.height:.1f} mm")
```

---

## ğŸ¨ ì‹œê°í™”

### ë‹¨ì¼ í˜ì´ì§€ ì‹œê°í™”

```python
from document_extractor import visualize_elements

# ê¸°ë³¸ ì‹œê°í™” (ì²« ë²ˆì§¸ í˜ì´ì§€)
visualize_elements(extracted, "output.png")

# íŠ¹ì • í˜ì´ì§€ ì§€ì •
visualize_elements(extracted, "page2.png", page_num=1)

# ì˜µì…˜ ì„¤ì •
visualize_elements(
    extracted,
    output_path="detailed.png",
    page_num=0,           # í‘œì‹œí•  í˜ì´ì§€ (0ë¶€í„°)
    show_bbox=True,       # ë°”ìš´ë”© ë°•ìŠ¤ í‘œì‹œ
    show_text=True,       # í…ìŠ¤íŠ¸ í‘œì‹œ
    show_type_colors=True,# ìš”ì†Œ ìœ í˜•ë³„ ìƒ‰ìƒ
    scale=3.0,            # í™•ëŒ€ ë¹„ìœ¨ (1mm = 3px)
    font_size=10          # í°íŠ¸ í¬ê¸°
)
```

### ì „ì²´ í˜ì´ì§€ ì‹œê°í™”

```python
from document_extractor import create_visualization_report

# ëª¨ë“  í˜ì´ì§€ë¥¼ ê°œë³„ ì´ë¯¸ì§€ë¡œ ì €ì¥ + JSON + í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€
create_visualization_report(extracted, "output_dir/")

# ê²°ê³¼:
#   output_dir/ë¬¸ì„œëª…_page_001.png
#   output_dir/ë¬¸ì„œëª…_page_002.png
#   output_dir/ë¬¸ì„œëª…_extracted.json
#   output_dir/ë¬¸ì„œëª…_structured.txt
#   output_dir/ë¬¸ì„œëª…_tables.md (í‘œê°€ ìˆëŠ” ê²½ìš°)
#   output_dir/ë¬¸ì„œëª…_images.json (ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°)
#   output_dir/ë¬¸ì„œëª…_images.md (ì´ë¯¸ì§€ ëª©ë¡)
#   output_dir/images/ (ì¶”ì¶œëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤)
```

### ìƒ‰ìƒ ë²”ë¡€

| ìš”ì†Œ ìœ í˜• | ìƒ‰ìƒ |
|----------|------|
| heading | ë¶„í™ìƒ‰ (#E91E63) |
| paragraph | íŒŒë€ìƒ‰ (#2196F3) |
| table | ë…¹ìƒ‰ (#4CAF50) |
| table_cell | ì£¼í™©ìƒ‰ (#FF9800) |

---

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
by_cursor/
â”œâ”€â”€ hwpx_parser_cursor.py    # HWPX íŒŒì„œ (XML ê¸°ë°˜)
â”œâ”€â”€ hwp_parser_cursor.py     # HWP íŒŒì„œ (OLE ë°”ì´ë„ˆë¦¬)
â”œâ”€â”€ document_extractor.py    # í†µí•© ì¶”ì¶œ ë° ì‹œê°í™” ëª¨ë“ˆ
â”œâ”€â”€ image_extractor.py       # ì´ë¯¸ì§€ ì¶”ì¶œ ëª¨ë“ˆ (NEW!)
â”œâ”€â”€ demo_usage.py            # ì‚¬ìš© ì˜ˆì‹œ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ test_parsers.py          # í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ README.md                # ì´ íŒŒì¼
â””â”€â”€ results/                 # ê²°ê³¼ ì¶œë ¥ í´ë”
    â”œâ”€â”€ hwp_extracted/
    â”‚   â””â”€â”€ images/          # ì¶”ì¶œëœ ì´ë¯¸ì§€
    â””â”€â”€ hwpx_extracted/
        â””â”€â”€ images/          # ì¶”ì¶œëœ ì´ë¯¸ì§€
```

---

## ğŸ“Š ì¶œë ¥ í˜•ì‹

### ExtractedDocument êµ¬ì¡°

```python
ExtractedDocument(
    title="ë¬¸ì„œì œëª©",
    source_file="ê²½ë¡œ",
    file_type="hwpx" | "hwp",
    pages=[PageInfo(...)],          # ëª¨ë“  í˜ì´ì§€ ì •ë³´
    elements=[DocumentElement(...)], # ëª¨ë“  ìš”ì†Œ (page í•„ë“œë¡œ êµ¬ë¶„)
    tables=[TableStructure(...)],
    headings=[DocumentElement(...)],
    paragraphs=[DocumentElement(...)],
    images=[ImageElement(...)],      # ì¶”ì¶œëœ ì´ë¯¸ì§€ (NEW!)
    metadata={...}
)
```

### ImageElement êµ¬ì¡°

```python
ImageElement(
    image_id="BIN0001",
    filename="BIN0001.jpg",
    format="jpg",
    bbox=BoundingBox(x=20.0, y=50.0, width=150.0, height=100.0),
    page=0,                          # ì´ë¯¸ì§€ê°€ ì†í•œ í˜ì´ì§€
    pixel_width=2481,                # í”½ì…€ ë„ˆë¹„
    pixel_height=3508,               # í”½ì…€ ë†’ì´
    file_size=977927,                # íŒŒì¼ í¬ê¸° (bytes)
    saved_path="/path/to/image",     # ì €ì¥ëœ ê²½ë¡œ
    ocr_text=""                      # ì™¸ë¶€ OCR ê²°ê³¼
)
```

---

## ì™„ì „í•œ ì˜ˆì‹œ: ë¬¸ì„œ íŒŒì‹±ë¶€í„° OCR ì—°ë™ê¹Œì§€

```python
from pathlib import Path
from hwp_parser_cursor import parse_hwp
from document_extractor import extract_document_with_images, create_visualization_report

# 1. ë¬¸ì„œ íŒŒì‹±
hwp_file = Path("document.hwp")
doc = parse_hwp(hwp_file)

# 2. ì´ë¯¸ì§€ í¬í•¨ êµ¬ì¡°í™”ëœ ì •ë³´ ì¶”ì¶œ
output_dir = Path("output")
extracted = extract_document_with_images(
    doc,
    extract_images=True,
    save_images_dir=output_dir / "images"
)

# 3. ì „ì²´ ë¦¬í¬íŠ¸ ìƒì„±
saved_files = create_visualization_report(extracted, output_dir)

print(f"âœ… ì´ {len(saved_files)}ê°œ íŒŒì¼ ìƒì„±")
print(f"  - í…ìŠ¤íŠ¸ ìš”ì†Œ: {len(extracted.elements)}ê°œ")
print(f"  - í‘œ: {len(extracted.tables)}ê°œ")
print(f"  - ì´ë¯¸ì§€: {len(extracted.images)}ê°œ")
print(f"  - í˜ì´ì§€: {len(extracted.pages)}ê°œ")

# 4. ì´ë¯¸ì§€ ì •ë³´ í™•ì¸
for img in extracted.images:
    print(f"\nì´ë¯¸ì§€: {img.filename}")
    print(f"  - í˜•ì‹: {img.format.upper()}")
    print(f"  - í¬ê¸°: {img.file_size:,} bytes")
    print(f"  - í•´ìƒë„: {img.pixel_width}Ã—{img.pixel_height} px")
    print(f"  - ìœ„ì¹˜: ({img.bbox.x:.1f}, {img.bbox.y:.1f}) mm")
    print(f"  - í˜ì´ì§€: {img.page + 1}")
    print(f"  - ì €ì¥ ê²½ë¡œ: {img.saved_path}")

# 5. (ì„ íƒ) ì™¸ë¶€ OCR ì—°ë™
import json

images_json_path = output_dir / f"{extracted.title}_images.json"
with open(images_json_path, "r", encoding="utf-8") as f:
    images_data = json.load(f)

for img_data in images_data["images"]:
    image_path = img_data["saved_path"]
    
    # ì—¬ê¸°ì— OCR ë¡œì§ ì¶”ê°€
    # ocr_result = your_ocr_api(image_path)
    # img_data["ocr_text"] = ocr_result["text"]
    # img_data["ocr_confidence"] = ocr_result["confidence"]

# ì—…ë°ì´íŠ¸ëœ JSON ì €ì¥
with open(images_json_path, "w", encoding="utf-8") as f:
    json.dump(images_data, f, ensure_ascii=False, indent=2)

print(f"\nâœ… OCR ì—°ë™ ì¤€ë¹„ ì™„ë£Œ: {images_json_path}")
```

---

## ğŸ’¡ LLM/RAG í™œìš© íŒ

### 1. ì´ë¯¸ì§€ ìœ„ì¹˜ ê¸°ë°˜ ë¬¸ë§¥ ì¶”ì¶œ

```python
# ì´ë¯¸ì§€ ì£¼ë³€ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì´ë¯¸ì§€ ì„¤ëª… ìº¡ì²˜)
for img in extracted.images:
    # ì´ë¯¸ì§€ì™€ ê°™ì€ í˜ì´ì§€ì˜ ìš”ì†Œë“¤
    page_elements = [e for e in extracted.elements if e.page == img.page]
    
    # ì´ë¯¸ì§€ ìœ„/ì•„ë˜ì˜ í…ìŠ¤íŠ¸ ì°¾ê¸°
    nearby_texts = []
    for elem in page_elements:
        # ì´ë¯¸ì§€ ë°”ë¡œ ìœ„ ë˜ëŠ” ì•„ë˜ 50mm ì´ë‚´
        if abs(elem.bbox.y - img.bbox.y) < 50:
            nearby_texts.append(elem.text)
    
    print(f"ì´ë¯¸ì§€ {img.filename} ì£¼ë³€ í…ìŠ¤íŠ¸:")
    print("\n".join(nearby_texts))
```

### 2. ì´ë¯¸ì§€ì™€ í‘œì˜ í†µí•©

```python
# ì´ë¯¸ì§€ì™€ í‘œë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ RAG ì²­í¬ ìƒì„±
all_content = []

for page_num in range(len(extracted.pages)):
    page_content = {
        "page": page_num + 1,
        "text_elements": [e for e in extracted.elements if e.page == page_num],
        "tables": [t for t in extracted.tables if t.page == page_num],
        "images": [i for i in extracted.images if i.page == page_num]
    }
    all_content.append(page_content)
```

### 3. í˜ì´ì§€ë³„ ì²­í‚¹ (RAGìš©)

```python
# í˜ì´ì§€ë³„ë¡œ ì²­í¬ ìƒì„± (ì´ë¯¸ì§€ í¬í•¨)
chunks = []
for page_num in range(len(extracted.pages)):
    page_elements = [e for e in extracted.elements if e.page == page_num]
    page_images = [i for i in extracted.images if i.page == page_num]
    
    page_text = "\n".join(e.text for e in page_elements if e.text.strip())
    
    chunks.append({
        "page": page_num + 1,
        "text": page_text,
        "image_count": len(page_images),
        "image_files": [i.saved_path for i in page_images],
        "metadata": {
            "source": extracted.source_file,
            "page": page_num + 1,
            "total_pages": len(extracted.pages)
        }
    })
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

```bash
# ë°ëª¨ ì‹¤í–‰
python demo_usage.py

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python document_extractor.py  # ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
python image_extractor.py     # ì´ë¯¸ì§€ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
```

---

## ğŸ“‹ ìš”êµ¬ì‚¬í•­

- Python 3.7+
- olefile (HWP íŒŒì‹±ìš©)
- Pillow (ì‹œê°í™” ë° ì´ë¯¸ì§€ ì¶”ì¶œìš©)
- ImageMagick (WMF/EMF ë³€í™˜ìš©, ì„ íƒ)

---

## ì§€ì› í˜•ì‹

### ë¬¸ì„œ í˜•ì‹

| í˜•ì‹ | í™•ì¥ì | ì„¤ëª… |
|------|--------|------|
| HWPX | .hwpx | í•œê¸€ 2014 ì´í›„ XML ê¸°ë°˜ í˜•ì‹ (ZIP ì••ì¶•) |
| HWP | .hwp | í•œê¸€ 97 ì´í›„ OLE ê¸°ë°˜ í˜•ì‹ |

### ì´ë¯¸ì§€ í˜•ì‹

| í˜•ì‹ | ì§€ì› | ë¹„ê³  |
|------|------|------|
| JPEG | âœ… | ì§ì ‘ ì¶”ì¶œ |
| PNG | âœ… | ì§ì ‘ ì¶”ì¶œ |
| BMP | âœ… | zlib ì••ì¶• í•´ì œ ì§€ì› |
| GIF | âœ… | ì§ì ‘ ì¶”ì¶œ |
| WMF | âœ… | PNG ë³€í™˜ í•„ìš” (ImageMagick/LibreOffice) |
| EMF | âœ… | PNG ë³€í™˜ í•„ìš” (ImageMagick/LibreOffice) |

---

## ğŸ“ ë¼ì´ì„¼ìŠ¤

MIT License

---

## ğŸ¤ ê¸°ì—¬

ì´ìŠˆì™€ PRì„ í™˜ì˜í•©ë‹ˆë‹¤!

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [HWPX íŒŒì¼ í˜•ì‹ ëª…ì„¸](https://www.hancom.com/etc/hwpDownload.do)
- [HWP íŒŒì¼ í˜•ì‹ (OLE Compound Document)](https://github.com/hancom-io/hwpx-spec)
